{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ea415d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanika\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0097 - loss: 1.1227 - val_accuracy: 0.0273 - val_loss: 0.7799\n",
      "Epoch 2/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0446 - loss: 0.7269 - val_accuracy: 0.0627 - val_loss: 0.7110\n",
      "Epoch 3/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0659 - loss: 0.6999 - val_accuracy: 0.0907 - val_loss: 0.6905\n",
      "Epoch 4/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0916 - loss: 0.6698 - val_accuracy: 0.0900 - val_loss: 0.6797\n",
      "Epoch 5/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0931 - loss: 0.6701 - val_accuracy: 0.1007 - val_loss: 0.6721\n",
      "Epoch 6/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1047 - loss: 0.6942 - val_accuracy: 0.1113 - val_loss: 0.6662\n",
      "Epoch 7/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1056 - loss: 0.6514 - val_accuracy: 0.1253 - val_loss: 0.6614\n",
      "Epoch 8/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1200 - loss: 0.6484 - val_accuracy: 0.1393 - val_loss: 0.6578\n",
      "Epoch 9/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1269 - loss: 0.6682 - val_accuracy: 0.1607 - val_loss: 0.6550\n",
      "Epoch 10/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1298 - loss: 0.6799 - val_accuracy: 0.1647 - val_loss: 0.6529\n",
      "Epoch 11/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1453 - loss: 0.6587 - val_accuracy: 0.1627 - val_loss: 0.6511\n",
      "Epoch 12/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1451 - loss: 0.6356 - val_accuracy: 0.1620 - val_loss: 0.6496\n",
      "Epoch 13/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1439 - loss: 0.6229 - val_accuracy: 0.1607 - val_loss: 0.6483\n",
      "Epoch 14/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1553 - loss: 0.6344 - val_accuracy: 0.1673 - val_loss: 0.6472\n",
      "Epoch 15/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1598 - loss: 0.6425 - val_accuracy: 0.1693 - val_loss: 0.6462\n",
      "Epoch 16/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1568 - loss: 0.6438 - val_accuracy: 0.1707 - val_loss: 0.6455\n",
      "Epoch 17/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1597 - loss: 0.6189 - val_accuracy: 0.1667 - val_loss: 0.6447\n",
      "Epoch 18/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1451 - loss: 0.5985 - val_accuracy: 0.1720 - val_loss: 0.6441\n",
      "Epoch 19/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1492 - loss: 0.6268 - val_accuracy: 0.1720 - val_loss: 0.6435\n",
      "Epoch 20/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1693 - loss: 0.6402 - val_accuracy: 0.1680 - val_loss: 0.6430\n",
      "Epoch 21/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1683 - loss: 0.6348 - val_accuracy: 0.1793 - val_loss: 0.6425\n",
      "Epoch 22/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1762 - loss: 0.6072 - val_accuracy: 0.1720 - val_loss: 0.6421\n",
      "Epoch 23/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1848 - loss: 0.6226 - val_accuracy: 0.1773 - val_loss: 0.6417\n",
      "Epoch 24/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1755 - loss: 0.6207 - val_accuracy: 0.1733 - val_loss: 0.6414\n",
      "Epoch 25/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1809 - loss: 0.6577 - val_accuracy: 0.1740 - val_loss: 0.6410\n",
      "Epoch 26/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1797 - loss: 0.6414 - val_accuracy: 0.1800 - val_loss: 0.6407\n",
      "Epoch 27/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1796 - loss: 0.6398 - val_accuracy: 0.1747 - val_loss: 0.6404\n",
      "Epoch 28/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1799 - loss: 0.6288 - val_accuracy: 0.1873 - val_loss: 0.6401\n",
      "Epoch 29/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1858 - loss: 0.6621 - val_accuracy: 0.1767 - val_loss: 0.6399\n",
      "Epoch 30/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1850 - loss: 0.6284 - val_accuracy: 0.1907 - val_loss: 0.6396\n",
      "Epoch 31/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2012 - loss: 0.6353 - val_accuracy: 0.1767 - val_loss: 0.6394\n",
      "Epoch 32/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1870 - loss: 0.6210 - val_accuracy: 0.1880 - val_loss: 0.6392\n",
      "Epoch 33/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2021 - loss: 0.6537 - val_accuracy: 0.1887 - val_loss: 0.6390\n",
      "Epoch 34/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1966 - loss: 0.6256 - val_accuracy: 0.1907 - val_loss: 0.6388\n",
      "Epoch 35/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1910 - loss: 0.6249 - val_accuracy: 0.2040 - val_loss: 0.6386\n",
      "Epoch 36/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2062 - loss: 0.6191 - val_accuracy: 0.2020 - val_loss: 0.6384\n",
      "Epoch 37/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2059 - loss: 0.6311 - val_accuracy: 0.2047 - val_loss: 0.6382\n",
      "Epoch 38/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2077 - loss: 0.6092 - val_accuracy: 0.2053 - val_loss: 0.6381\n",
      "Epoch 39/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2055 - loss: 0.6381 - val_accuracy: 0.2047 - val_loss: 0.6379\n",
      "Epoch 40/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2214 - loss: 0.6172 - val_accuracy: 0.2160 - val_loss: 0.6378\n",
      "Epoch 41/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2166 - loss: 0.6114 - val_accuracy: 0.2093 - val_loss: 0.6376\n",
      "Epoch 42/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2065 - loss: 0.6255 - val_accuracy: 0.2147 - val_loss: 0.6375\n",
      "Epoch 43/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2188 - loss: 0.6511 - val_accuracy: 0.2127 - val_loss: 0.6373\n",
      "Epoch 44/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2191 - loss: 0.6428 - val_accuracy: 0.2187 - val_loss: 0.6371\n",
      "Epoch 45/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2239 - loss: 0.6615 - val_accuracy: 0.2113 - val_loss: 0.6370\n",
      "Epoch 46/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2178 - loss: 0.6530 - val_accuracy: 0.2187 - val_loss: 0.6369\n",
      "Epoch 47/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2316 - loss: 0.6378 - val_accuracy: 0.2187 - val_loss: 0.6367\n",
      "Epoch 48/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2240 - loss: 0.6158 - val_accuracy: 0.2180 - val_loss: 0.6366\n",
      "Epoch 49/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2235 - loss: 0.6360 - val_accuracy: 0.2173 - val_loss: 0.6365\n",
      "Epoch 50/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2196 - loss: 0.6247 - val_accuracy: 0.2173 - val_loss: 0.6363\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2242 - loss: 0.6263 - val_accuracy: 0.2300 - val_loss: 0.6362\n",
      "Epoch 52/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2225 - loss: 0.6328 - val_accuracy: 0.2180 - val_loss: 0.6360\n",
      "Epoch 53/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2392 - loss: 0.6136 - val_accuracy: 0.2227 - val_loss: 0.6359\n",
      "Epoch 54/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2207 - loss: 0.6562 - val_accuracy: 0.2213 - val_loss: 0.6358\n",
      "Epoch 55/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2437 - loss: 0.6387 - val_accuracy: 0.2273 - val_loss: 0.6357\n",
      "Epoch 56/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2313 - loss: 0.6289 - val_accuracy: 0.2273 - val_loss: 0.6355\n",
      "Epoch 57/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2397 - loss: 0.6057 - val_accuracy: 0.2273 - val_loss: 0.6354\n",
      "Epoch 58/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2482 - loss: 0.5995 - val_accuracy: 0.2307 - val_loss: 0.6353\n",
      "Epoch 59/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2316 - loss: 0.6151 - val_accuracy: 0.2353 - val_loss: 0.6352\n",
      "Epoch 60/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2442 - loss: 0.6147 - val_accuracy: 0.2380 - val_loss: 0.6351\n",
      "Epoch 61/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2317 - loss: 0.6150 - val_accuracy: 0.2313 - val_loss: 0.6350\n",
      "Epoch 62/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2394 - loss: 0.6383 - val_accuracy: 0.2453 - val_loss: 0.6349\n",
      "Epoch 63/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2475 - loss: 0.6278 - val_accuracy: 0.2413 - val_loss: 0.6347\n",
      "Epoch 64/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2505 - loss: 0.6237 - val_accuracy: 0.2287 - val_loss: 0.6346\n",
      "Epoch 65/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2421 - loss: 0.6281 - val_accuracy: 0.2427 - val_loss: 0.6345\n",
      "Epoch 66/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2388 - loss: 0.6482 - val_accuracy: 0.2373 - val_loss: 0.6344\n",
      "Epoch 67/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2359 - loss: 0.6560 - val_accuracy: 0.2440 - val_loss: 0.6343\n",
      "Epoch 68/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2441 - loss: 0.6152 - val_accuracy: 0.2400 - val_loss: 0.6342\n",
      "Epoch 69/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2568 - loss: 0.5817 - val_accuracy: 0.2480 - val_loss: 0.6341\n",
      "Epoch 70/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2376 - loss: 0.6251 - val_accuracy: 0.2367 - val_loss: 0.6340\n",
      "Epoch 71/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2471 - loss: 0.6172 - val_accuracy: 0.2507 - val_loss: 0.6340\n",
      "Epoch 72/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2381 - loss: 0.6673 - val_accuracy: 0.2447 - val_loss: 0.6338\n",
      "Epoch 73/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2494 - loss: 0.6482 - val_accuracy: 0.2480 - val_loss: 0.6338\n",
      "Epoch 74/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2460 - loss: 0.6189 - val_accuracy: 0.2540 - val_loss: 0.6336\n",
      "Epoch 75/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2517 - loss: 0.6182 - val_accuracy: 0.2433 - val_loss: 0.6336\n",
      "Epoch 76/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2446 - loss: 0.6494 - val_accuracy: 0.2527 - val_loss: 0.6335\n",
      "Epoch 77/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2502 - loss: 0.6215 - val_accuracy: 0.2467 - val_loss: 0.6334\n",
      "Epoch 78/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2551 - loss: 0.6065 - val_accuracy: 0.2533 - val_loss: 0.6334\n",
      "Epoch 79/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2354 - loss: 0.6449 - val_accuracy: 0.2587 - val_loss: 0.6332\n",
      "Epoch 80/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2569 - loss: 0.6232 - val_accuracy: 0.2540 - val_loss: 0.6332\n",
      "Epoch 81/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2507 - loss: 0.6077 - val_accuracy: 0.2593 - val_loss: 0.6332\n",
      "Epoch 82/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2428 - loss: 0.6385 - val_accuracy: 0.2573 - val_loss: 0.6330\n",
      "Epoch 83/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2530 - loss: 0.5735 - val_accuracy: 0.2500 - val_loss: 0.6330\n",
      "Epoch 84/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2539 - loss: 0.6368 - val_accuracy: 0.2507 - val_loss: 0.6329\n",
      "Epoch 85/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2518 - loss: 0.6464 - val_accuracy: 0.2633 - val_loss: 0.6329\n",
      "Epoch 86/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2547 - loss: 0.6387 - val_accuracy: 0.2653 - val_loss: 0.6328\n",
      "Epoch 87/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2638 - loss: 0.6299 - val_accuracy: 0.2620 - val_loss: 0.6327\n",
      "Epoch 88/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2692 - loss: 0.6206 - val_accuracy: 0.2613 - val_loss: 0.6327\n",
      "Epoch 89/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2611 - loss: 0.6063 - val_accuracy: 0.2560 - val_loss: 0.6326\n",
      "Epoch 90/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2625 - loss: 0.6228 - val_accuracy: 0.2620 - val_loss: 0.6326\n",
      "Epoch 91/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2520 - loss: 0.6486 - val_accuracy: 0.2633 - val_loss: 0.6325\n",
      "Epoch 92/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2512 - loss: 0.6317 - val_accuracy: 0.2627 - val_loss: 0.6324\n",
      "Epoch 93/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2587 - loss: 0.6624 - val_accuracy: 0.2733 - val_loss: 0.6324\n",
      "Epoch 94/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2608 - loss: 0.6296 - val_accuracy: 0.2740 - val_loss: 0.6323\n",
      "Epoch 95/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2732 - loss: 0.6145 - val_accuracy: 0.2667 - val_loss: 0.6322\n",
      "Epoch 96/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2631 - loss: 0.6098 - val_accuracy: 0.2607 - val_loss: 0.6321\n",
      "Epoch 97/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2778 - loss: 0.6391 - val_accuracy: 0.2640 - val_loss: 0.6321\n",
      "Epoch 98/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2696 - loss: 0.5920 - val_accuracy: 0.2733 - val_loss: 0.6321\n",
      "Epoch 99/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2763 - loss: 0.6383 - val_accuracy: 0.2653 - val_loss: 0.6320\n",
      "Epoch 100/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2677 - loss: 0.6150 - val_accuracy: 0.2773 - val_loss: 0.6319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2797 - loss: 0.6191\n",
      "Test Loss: [0.631919264793396, 0.2773333191871643]\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Confusion Matrix:\n",
      " [[575  47]\n",
      " [850  28]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.92      0.56       622\n",
      "         1.0       0.37      0.03      0.06       878\n",
      "\n",
      "    accuracy                           0.40      1500\n",
      "   macro avg       0.39      0.48      0.31      1500\n",
      "weighted avg       0.39      0.40      0.27      1500\n",
      "\n",
      "Number of outliers: 75\n",
      "Number of anomalies: 28\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import BatchNormalization, MaxPooling2D, Conv2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\Sanika\\Desktop\\Untitled Folder\\ecg.csv\", header = None)\n",
    "df\n",
    "\n",
    "X = df.drop([140], axis = 1)\n",
    "y = df[140]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train =  scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "encoder = Sequential([Dense(64, activation = 'relu', input_shape = (X_train.shape[1],))])\n",
    "decoder = Sequential([Dense(X_train.shape[1], activation = 'sigmoid')])\n",
    "\n",
    "autoencoder = Sequential([encoder, decoder])\n",
    "\n",
    "autoencoder.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "\n",
    "r = autoencoder.fit(X_train, X_train, epochs = 100, batch_size = 64, validation_data= (X_test, X_test))\n",
    "\n",
    "r.history.keys()\n",
    "\n",
    "plt.plot(r.history['loss'], label = 'loss', color = 'blue')\n",
    "plt.plot(r.history['val_loss'], label = 'val_loss', color = 'green')\n",
    "plt.legend\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.plot(r.history['accuracy'], label = 'acc', color = 'red')\n",
    "plt.plot(r.history['val_accuracy'], label = 'val_acc', color = 'green')\n",
    "plt.legend\n",
    "\n",
    "loss = autoencoder.evaluate(X_test, X_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "\n",
    "decoded_data = autoencoder.predict(X_test)\n",
    "mse = np.mean(np.power(X_test - decoded_data, 2), axis = 1)\n",
    "threshold = np.percentile(mse, 95)\n",
    "\n",
    "outliers = mse> threshold\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, outliers))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, outliers))\n",
    "\n",
    "num_outliers = np.sum(outliers)\n",
    "num_anomalies = np.sum(y_test[outliers] == 1)\n",
    "\n",
    "print(f'Number of outliers: {num_outliers}')\n",
    "print(f'Number of anomalies: {num_anomalies}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "679800e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bba86073",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\Sanika\\Desktop\\Untitled Folder\\ecg.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4593ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.112522</td>\n",
       "      <td>-2.827204</td>\n",
       "      <td>-3.773897</td>\n",
       "      <td>-4.349751</td>\n",
       "      <td>-4.376041</td>\n",
       "      <td>-3.474986</td>\n",
       "      <td>-2.181408</td>\n",
       "      <td>-1.818286</td>\n",
       "      <td>-1.250522</td>\n",
       "      <td>-0.477492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792168</td>\n",
       "      <td>0.933541</td>\n",
       "      <td>0.796958</td>\n",
       "      <td>0.578621</td>\n",
       "      <td>0.257740</td>\n",
       "      <td>0.228077</td>\n",
       "      <td>0.123431</td>\n",
       "      <td>0.925286</td>\n",
       "      <td>0.193137</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.100878</td>\n",
       "      <td>-3.996840</td>\n",
       "      <td>-4.285843</td>\n",
       "      <td>-4.506579</td>\n",
       "      <td>-4.022377</td>\n",
       "      <td>-3.234368</td>\n",
       "      <td>-1.566126</td>\n",
       "      <td>-0.992258</td>\n",
       "      <td>-0.754680</td>\n",
       "      <td>0.042321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538356</td>\n",
       "      <td>0.656881</td>\n",
       "      <td>0.787490</td>\n",
       "      <td>0.724046</td>\n",
       "      <td>0.555784</td>\n",
       "      <td>0.476333</td>\n",
       "      <td>0.773820</td>\n",
       "      <td>1.119621</td>\n",
       "      <td>-1.436250</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.567088</td>\n",
       "      <td>-2.593450</td>\n",
       "      <td>-3.874230</td>\n",
       "      <td>-4.584095</td>\n",
       "      <td>-4.187449</td>\n",
       "      <td>-3.151462</td>\n",
       "      <td>-1.742940</td>\n",
       "      <td>-1.490659</td>\n",
       "      <td>-1.183580</td>\n",
       "      <td>-0.394229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886073</td>\n",
       "      <td>0.531452</td>\n",
       "      <td>0.311377</td>\n",
       "      <td>-0.021919</td>\n",
       "      <td>-0.713683</td>\n",
       "      <td>-0.532197</td>\n",
       "      <td>0.321097</td>\n",
       "      <td>0.904227</td>\n",
       "      <td>-0.421797</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.490473</td>\n",
       "      <td>-1.914407</td>\n",
       "      <td>-3.616364</td>\n",
       "      <td>-4.318823</td>\n",
       "      <td>-4.268016</td>\n",
       "      <td>-3.881110</td>\n",
       "      <td>-2.993280</td>\n",
       "      <td>-1.671131</td>\n",
       "      <td>-1.333884</td>\n",
       "      <td>-0.965629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350816</td>\n",
       "      <td>0.499111</td>\n",
       "      <td>0.600345</td>\n",
       "      <td>0.842069</td>\n",
       "      <td>0.952074</td>\n",
       "      <td>0.990133</td>\n",
       "      <td>1.086798</td>\n",
       "      <td>1.403011</td>\n",
       "      <td>-0.383564</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.800232</td>\n",
       "      <td>-0.874252</td>\n",
       "      <td>-2.384761</td>\n",
       "      <td>-3.973292</td>\n",
       "      <td>-4.338224</td>\n",
       "      <td>-3.802422</td>\n",
       "      <td>-2.534510</td>\n",
       "      <td>-1.783423</td>\n",
       "      <td>-1.594450</td>\n",
       "      <td>-0.753199</td>\n",
       "      <td>...</td>\n",
       "      <td>1.148884</td>\n",
       "      <td>0.958434</td>\n",
       "      <td>1.059025</td>\n",
       "      <td>1.371682</td>\n",
       "      <td>1.277392</td>\n",
       "      <td>0.960304</td>\n",
       "      <td>0.971020</td>\n",
       "      <td>1.614392</td>\n",
       "      <td>1.421456</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>0.608558</td>\n",
       "      <td>-0.335651</td>\n",
       "      <td>-0.990948</td>\n",
       "      <td>-1.784153</td>\n",
       "      <td>-2.626145</td>\n",
       "      <td>-2.957065</td>\n",
       "      <td>-2.931897</td>\n",
       "      <td>-2.664816</td>\n",
       "      <td>-2.090137</td>\n",
       "      <td>-1.461841</td>\n",
       "      <td>...</td>\n",
       "      <td>1.757705</td>\n",
       "      <td>2.291923</td>\n",
       "      <td>2.704595</td>\n",
       "      <td>2.451519</td>\n",
       "      <td>2.017396</td>\n",
       "      <td>1.704358</td>\n",
       "      <td>1.688542</td>\n",
       "      <td>1.629593</td>\n",
       "      <td>1.342651</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>-2.060402</td>\n",
       "      <td>-2.860116</td>\n",
       "      <td>-3.405074</td>\n",
       "      <td>-3.748719</td>\n",
       "      <td>-3.513561</td>\n",
       "      <td>-3.006545</td>\n",
       "      <td>-2.234850</td>\n",
       "      <td>-1.593270</td>\n",
       "      <td>-1.075279</td>\n",
       "      <td>-0.976047</td>\n",
       "      <td>...</td>\n",
       "      <td>1.388947</td>\n",
       "      <td>2.079675</td>\n",
       "      <td>2.433375</td>\n",
       "      <td>2.159484</td>\n",
       "      <td>1.819747</td>\n",
       "      <td>1.534767</td>\n",
       "      <td>1.696818</td>\n",
       "      <td>1.483832</td>\n",
       "      <td>1.047612</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>-1.122969</td>\n",
       "      <td>-2.252925</td>\n",
       "      <td>-2.867628</td>\n",
       "      <td>-3.358605</td>\n",
       "      <td>-3.167849</td>\n",
       "      <td>-2.638360</td>\n",
       "      <td>-1.664162</td>\n",
       "      <td>-0.935655</td>\n",
       "      <td>-0.866953</td>\n",
       "      <td>-0.645363</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.472419</td>\n",
       "      <td>-1.310147</td>\n",
       "      <td>-2.029521</td>\n",
       "      <td>-3.221294</td>\n",
       "      <td>-4.176790</td>\n",
       "      <td>-4.009720</td>\n",
       "      <td>-2.874136</td>\n",
       "      <td>-2.008369</td>\n",
       "      <td>-1.808334</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>-0.547705</td>\n",
       "      <td>-1.889545</td>\n",
       "      <td>-2.839779</td>\n",
       "      <td>-3.457912</td>\n",
       "      <td>-3.929149</td>\n",
       "      <td>-3.966026</td>\n",
       "      <td>-3.492560</td>\n",
       "      <td>-2.695270</td>\n",
       "      <td>-1.849691</td>\n",
       "      <td>-1.374321</td>\n",
       "      <td>...</td>\n",
       "      <td>1.258419</td>\n",
       "      <td>1.907530</td>\n",
       "      <td>2.280888</td>\n",
       "      <td>1.895242</td>\n",
       "      <td>1.437702</td>\n",
       "      <td>1.193433</td>\n",
       "      <td>1.261335</td>\n",
       "      <td>1.150449</td>\n",
       "      <td>0.804932</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>-1.351779</td>\n",
       "      <td>-2.209006</td>\n",
       "      <td>-2.520225</td>\n",
       "      <td>-3.061475</td>\n",
       "      <td>-3.065141</td>\n",
       "      <td>-3.030739</td>\n",
       "      <td>-2.622720</td>\n",
       "      <td>-2.044092</td>\n",
       "      <td>-1.295874</td>\n",
       "      <td>-0.733839</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.512234</td>\n",
       "      <td>-2.076075</td>\n",
       "      <td>-2.586042</td>\n",
       "      <td>-3.322799</td>\n",
       "      <td>-3.627311</td>\n",
       "      <td>-3.437038</td>\n",
       "      <td>-2.260023</td>\n",
       "      <td>-1.577823</td>\n",
       "      <td>-0.684531</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4998 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -0.112522 -2.827204 -3.773897 -4.349751 -4.376041 -3.474986 -2.181408   \n",
       "1    -1.100878 -3.996840 -4.285843 -4.506579 -4.022377 -3.234368 -1.566126   \n",
       "2    -0.567088 -2.593450 -3.874230 -4.584095 -4.187449 -3.151462 -1.742940   \n",
       "3     0.490473 -1.914407 -3.616364 -4.318823 -4.268016 -3.881110 -2.993280   \n",
       "4     0.800232 -0.874252 -2.384761 -3.973292 -4.338224 -3.802422 -2.534510   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4993  0.608558 -0.335651 -0.990948 -1.784153 -2.626145 -2.957065 -2.931897   \n",
       "4994 -2.060402 -2.860116 -3.405074 -3.748719 -3.513561 -3.006545 -2.234850   \n",
       "4995 -1.122969 -2.252925 -2.867628 -3.358605 -3.167849 -2.638360 -1.664162   \n",
       "4996 -0.547705 -1.889545 -2.839779 -3.457912 -3.929149 -3.966026 -3.492560   \n",
       "4997 -1.351779 -2.209006 -2.520225 -3.061475 -3.065141 -3.030739 -2.622720   \n",
       "\n",
       "           7         8         9    ...       131       132       133  \\\n",
       "0    -1.818286 -1.250522 -0.477492  ...  0.792168  0.933541  0.796958   \n",
       "1    -0.992258 -0.754680  0.042321  ...  0.538356  0.656881  0.787490   \n",
       "2    -1.490659 -1.183580 -0.394229  ...  0.886073  0.531452  0.311377   \n",
       "3    -1.671131 -1.333884 -0.965629  ...  0.350816  0.499111  0.600345   \n",
       "4    -1.783423 -1.594450 -0.753199  ...  1.148884  0.958434  1.059025   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4993 -2.664816 -2.090137 -1.461841  ...  1.757705  2.291923  2.704595   \n",
       "4994 -1.593270 -1.075279 -0.976047  ...  1.388947  2.079675  2.433375   \n",
       "4995 -0.935655 -0.866953 -0.645363  ... -0.472419 -1.310147 -2.029521   \n",
       "4996 -2.695270 -1.849691 -1.374321  ...  1.258419  1.907530  2.280888   \n",
       "4997 -2.044092 -1.295874 -0.733839  ... -1.512234 -2.076075 -2.586042   \n",
       "\n",
       "           134       135       136       137       138       139  140  \n",
       "0     0.578621  0.257740  0.228077  0.123431  0.925286  0.193137  1.0  \n",
       "1     0.724046  0.555784  0.476333  0.773820  1.119621 -1.436250  1.0  \n",
       "2    -0.021919 -0.713683 -0.532197  0.321097  0.904227 -0.421797  1.0  \n",
       "3     0.842069  0.952074  0.990133  1.086798  1.403011 -0.383564  1.0  \n",
       "4     1.371682  1.277392  0.960304  0.971020  1.614392  1.421456  1.0  \n",
       "...        ...       ...       ...       ...       ...       ...  ...  \n",
       "4993  2.451519  2.017396  1.704358  1.688542  1.629593  1.342651  0.0  \n",
       "4994  2.159484  1.819747  1.534767  1.696818  1.483832  1.047612  0.0  \n",
       "4995 -3.221294 -4.176790 -4.009720 -2.874136 -2.008369 -1.808334  0.0  \n",
       "4996  1.895242  1.437702  1.193433  1.261335  1.150449  0.804932  0.0  \n",
       "4997 -3.322799 -3.627311 -3.437038 -2.260023 -1.577823 -0.684531  0.0  \n",
       "\n",
       "[4998 rows x 141 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0823ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(140,axis=1)\n",
    "y=data[140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb67117d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.112522</td>\n",
       "      <td>-2.827204</td>\n",
       "      <td>-3.773897</td>\n",
       "      <td>-4.349751</td>\n",
       "      <td>-4.376041</td>\n",
       "      <td>-3.474986</td>\n",
       "      <td>-2.181408</td>\n",
       "      <td>-1.818286</td>\n",
       "      <td>-1.250522</td>\n",
       "      <td>-0.477492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160348</td>\n",
       "      <td>0.792168</td>\n",
       "      <td>0.933541</td>\n",
       "      <td>0.796958</td>\n",
       "      <td>0.578621</td>\n",
       "      <td>0.257740</td>\n",
       "      <td>0.228077</td>\n",
       "      <td>0.123431</td>\n",
       "      <td>0.925286</td>\n",
       "      <td>0.193137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.100878</td>\n",
       "      <td>-3.996840</td>\n",
       "      <td>-4.285843</td>\n",
       "      <td>-4.506579</td>\n",
       "      <td>-4.022377</td>\n",
       "      <td>-3.234368</td>\n",
       "      <td>-1.566126</td>\n",
       "      <td>-0.992258</td>\n",
       "      <td>-0.754680</td>\n",
       "      <td>0.042321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560327</td>\n",
       "      <td>0.538356</td>\n",
       "      <td>0.656881</td>\n",
       "      <td>0.787490</td>\n",
       "      <td>0.724046</td>\n",
       "      <td>0.555784</td>\n",
       "      <td>0.476333</td>\n",
       "      <td>0.773820</td>\n",
       "      <td>1.119621</td>\n",
       "      <td>-1.436250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.567088</td>\n",
       "      <td>-2.593450</td>\n",
       "      <td>-3.874230</td>\n",
       "      <td>-4.584095</td>\n",
       "      <td>-4.187449</td>\n",
       "      <td>-3.151462</td>\n",
       "      <td>-1.742940</td>\n",
       "      <td>-1.490659</td>\n",
       "      <td>-1.183580</td>\n",
       "      <td>-0.394229</td>\n",
       "      <td>...</td>\n",
       "      <td>1.284825</td>\n",
       "      <td>0.886073</td>\n",
       "      <td>0.531452</td>\n",
       "      <td>0.311377</td>\n",
       "      <td>-0.021919</td>\n",
       "      <td>-0.713683</td>\n",
       "      <td>-0.532197</td>\n",
       "      <td>0.321097</td>\n",
       "      <td>0.904227</td>\n",
       "      <td>-0.421797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.490473</td>\n",
       "      <td>-1.914407</td>\n",
       "      <td>-3.616364</td>\n",
       "      <td>-4.318823</td>\n",
       "      <td>-4.268016</td>\n",
       "      <td>-3.881110</td>\n",
       "      <td>-2.993280</td>\n",
       "      <td>-1.671131</td>\n",
       "      <td>-1.333884</td>\n",
       "      <td>-0.965629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491173</td>\n",
       "      <td>0.350816</td>\n",
       "      <td>0.499111</td>\n",
       "      <td>0.600345</td>\n",
       "      <td>0.842069</td>\n",
       "      <td>0.952074</td>\n",
       "      <td>0.990133</td>\n",
       "      <td>1.086798</td>\n",
       "      <td>1.403011</td>\n",
       "      <td>-0.383564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.800232</td>\n",
       "      <td>-0.874252</td>\n",
       "      <td>-2.384761</td>\n",
       "      <td>-3.973292</td>\n",
       "      <td>-4.338224</td>\n",
       "      <td>-3.802422</td>\n",
       "      <td>-2.534510</td>\n",
       "      <td>-1.783423</td>\n",
       "      <td>-1.594450</td>\n",
       "      <td>-0.753199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966606</td>\n",
       "      <td>1.148884</td>\n",
       "      <td>0.958434</td>\n",
       "      <td>1.059025</td>\n",
       "      <td>1.371682</td>\n",
       "      <td>1.277392</td>\n",
       "      <td>0.960304</td>\n",
       "      <td>0.971020</td>\n",
       "      <td>1.614392</td>\n",
       "      <td>1.421456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.112522 -2.827204 -3.773897 -4.349751 -4.376041 -3.474986 -2.181408   \n",
       "1 -1.100878 -3.996840 -4.285843 -4.506579 -4.022377 -3.234368 -1.566126   \n",
       "2 -0.567088 -2.593450 -3.874230 -4.584095 -4.187449 -3.151462 -1.742940   \n",
       "3  0.490473 -1.914407 -3.616364 -4.318823 -4.268016 -3.881110 -2.993280   \n",
       "4  0.800232 -0.874252 -2.384761 -3.973292 -4.338224 -3.802422 -2.534510   \n",
       "\n",
       "        7         8         9    ...       130       131       132       133  \\\n",
       "0 -1.818286 -1.250522 -0.477492  ...  0.160348  0.792168  0.933541  0.796958   \n",
       "1 -0.992258 -0.754680  0.042321  ...  0.560327  0.538356  0.656881  0.787490   \n",
       "2 -1.490659 -1.183580 -0.394229  ...  1.284825  0.886073  0.531452  0.311377   \n",
       "3 -1.671131 -1.333884 -0.965629  ...  0.491173  0.350816  0.499111  0.600345   \n",
       "4 -1.783423 -1.594450 -0.753199  ...  0.966606  1.148884  0.958434  1.059025   \n",
       "\n",
       "        134       135       136       137       138       139  \n",
       "0  0.578621  0.257740  0.228077  0.123431  0.925286  0.193137  \n",
       "1  0.724046  0.555784  0.476333  0.773820  1.119621 -1.436250  \n",
       "2 -0.021919 -0.713683 -0.532197  0.321097  0.904227 -0.421797  \n",
       "3  0.842069  0.952074  0.990133  1.086798  1.403011 -0.383564  \n",
       "4  1.371682  1.277392  0.960304  0.971020  1.614392  1.421456  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "960b16c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b8eb9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1c65077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3498, 140)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0ad7cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder= Sequential([\n",
    "    Dense(64,activation='relu',input_shape=(x_train.shape[1],))\n",
    "])\n",
    "\n",
    "decoder= Sequential([\n",
    "    Dense((x_train.shape[1]),activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "296ea887",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder= Sequential([encoder,decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "259ba7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3f8fb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -116.9884 - mean_squared_error: 0.9887 - val_loss: -956.2291 - val_mean_squared_error: 0.9862\n",
      "Epoch 2/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -1746.9635 - mean_squared_error: 0.9859 - val_loss: -5255.7549 - val_mean_squared_error: 0.9864\n",
      "Epoch 3/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -7167.7314 - mean_squared_error: 0.9866 - val_loss: -14363.5811 - val_mean_squared_error: 0.9866\n",
      "Epoch 4/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -17545.0898 - mean_squared_error: 0.9870 - val_loss: -28405.3633 - val_mean_squared_error: 0.9874\n",
      "Epoch 5/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -33009.2852 - mean_squared_error: 0.9873 - val_loss: -47327.8086 - val_mean_squared_error: 0.9873\n",
      "Epoch 6/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -52819.0312 - mean_squared_error: 0.9874 - val_loss: -70867.0781 - val_mean_squared_error: 0.9879\n",
      "Epoch 7/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -77796.5312 - mean_squared_error: 0.9875 - val_loss: -98814.9219 - val_mean_squared_error: 0.9875\n",
      "Epoch 8/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -106655.7656 - mean_squared_error: 0.9877 - val_loss: -131240.4844 - val_mean_squared_error: 0.9877\n",
      "Epoch 9/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -139170.2188 - mean_squared_error: 0.9877 - val_loss: -167844.1562 - val_mean_squared_error: 0.9879\n",
      "Epoch 10/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -180399.2656 - mean_squared_error: 0.9878 - val_loss: -208721.4219 - val_mean_squared_error: 0.9874\n",
      "Epoch 11/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -220176.7188 - mean_squared_error: 0.9878 - val_loss: -253400.4062 - val_mean_squared_error: 0.9871\n",
      "Epoch 12/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -264148.1250 - mean_squared_error: 0.9880 - val_loss: -302142.6875 - val_mean_squared_error: 0.9877\n",
      "Epoch 13/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -318940.1875 - mean_squared_error: 0.9878 - val_loss: -354792.7812 - val_mean_squared_error: 0.9880\n",
      "Epoch 14/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -369540.3438 - mean_squared_error: 0.9881 - val_loss: -411074.5312 - val_mean_squared_error: 0.9877\n",
      "Epoch 15/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -426160.3125 - mean_squared_error: 0.9881 - val_loss: -471288.5625 - val_mean_squared_error: 0.9874\n",
      "Epoch 16/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -493855.0000 - mean_squared_error: 0.9879 - val_loss: -535160.0625 - val_mean_squared_error: 0.9872\n",
      "Epoch 17/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -554154.0625 - mean_squared_error: 0.9879 - val_loss: -602179.5625 - val_mean_squared_error: 0.9877\n",
      "Epoch 18/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -621069.8750 - mean_squared_error: 0.9880 - val_loss: -673280.5000 - val_mean_squared_error: 0.9881\n",
      "Epoch 19/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -696780.0625 - mean_squared_error: 0.9881 - val_loss: -747381.5625 - val_mean_squared_error: 0.9874\n",
      "Epoch 20/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -762849.6250 - mean_squared_error: 0.9879 - val_loss: -825268.2500 - val_mean_squared_error: 0.9879\n",
      "Epoch 21/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -851897.6250 - mean_squared_error: 0.9884 - val_loss: -906226.0000 - val_mean_squared_error: 0.9884\n",
      "Epoch 22/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -942628.5625 - mean_squared_error: 0.9879 - val_loss: -990580.3750 - val_mean_squared_error: 0.9883\n",
      "Epoch 23/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -997202.3125 - mean_squared_error: 0.9884 - val_loss: -1077741.1250 - val_mean_squared_error: 0.9880\n",
      "Epoch 24/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1122613.2500 - mean_squared_error: 0.9877 - val_loss: -1168548.3750 - val_mean_squared_error: 0.9880\n",
      "Epoch 25/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1191559.5000 - mean_squared_error: 0.9880 - val_loss: -1261927.8750 - val_mean_squared_error: 0.9869\n",
      "Epoch 26/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1285137.8750 - mean_squared_error: 0.9880 - val_loss: -1358992.0000 - val_mean_squared_error: 0.9873\n",
      "Epoch 27/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1390394.8750 - mean_squared_error: 0.9880 - val_loss: -1458713.3750 - val_mean_squared_error: 0.9888\n",
      "Epoch 28/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -1485854.5000 - mean_squared_error: 0.9882 - val_loss: -1561079.7500 - val_mean_squared_error: 0.9875\n",
      "Epoch 29/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -1576455.8750 - mean_squared_error: 0.9882 - val_loss: -1666542.1250 - val_mean_squared_error: 0.9883\n",
      "Epoch 30/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -1681502.8750 - mean_squared_error: 0.9879 - val_loss: -1774759.6250 - val_mean_squared_error: 0.9871\n",
      "Epoch 31/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -1785154.7500 - mean_squared_error: 0.9881 - val_loss: -1886351.8750 - val_mean_squared_error: 0.9876\n",
      "Epoch 32/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -1930875.6250 - mean_squared_error: 0.9877 - val_loss: -2000407.2500 - val_mean_squared_error: 0.9875\n",
      "Epoch 33/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -2060817.0000 - mean_squared_error: 0.9878 - val_loss: -2117803.7500 - val_mean_squared_error: 0.9877\n",
      "Epoch 34/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -2186786.0000 - mean_squared_error: 0.9879 - val_loss: -2237439.5000 - val_mean_squared_error: 0.9890\n",
      "Epoch 35/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -2273512.5000 - mean_squared_error: 0.9880 - val_loss: -2358986.5000 - val_mean_squared_error: 0.9876\n",
      "Epoch 36/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -2406346.7500 - mean_squared_error: 0.9878 - val_loss: -2484440.0000 - val_mean_squared_error: 0.9884\n",
      "Epoch 37/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -2530697.2500 - mean_squared_error: 0.9877 - val_loss: -2611537.2500 - val_mean_squared_error: 0.9880\n",
      "Epoch 38/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -2659563.2500 - mean_squared_error: 0.9880 - val_loss: -2741827.0000 - val_mean_squared_error: 0.9896\n",
      "Epoch 39/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -2771170.5000 - mean_squared_error: 0.9881 - val_loss: -2874639.0000 - val_mean_squared_error: 0.9881\n",
      "Epoch 40/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -2895999.5000 - mean_squared_error: 0.9879 - val_loss: -3009975.0000 - val_mean_squared_error: 0.9878\n",
      "Epoch 41/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -3103619.5000 - mean_squared_error: 0.9876 - val_loss: -3148130.2500 - val_mean_squared_error: 0.9899\n",
      "Epoch 42/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -3248213.2500 - mean_squared_error: 0.9879 - val_loss: -3288344.5000 - val_mean_squared_error: 0.9873\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -3368207.7500 - mean_squared_error: 0.9878 - val_loss: -3430440.2500 - val_mean_squared_error: 0.9885\n",
      "Epoch 44/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -3522962.5000 - mean_squared_error: 0.9877 - val_loss: -3576167.5000 - val_mean_squared_error: 0.9884\n",
      "Epoch 45/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -3611316.2500 - mean_squared_error: 0.9879 - val_loss: -3723393.7500 - val_mean_squared_error: 0.9867\n",
      "Epoch 46/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -3819901.2500 - mean_squared_error: 0.9878 - val_loss: -3874311.7500 - val_mean_squared_error: 0.9872\n",
      "Epoch 47/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -3887497.5000 - mean_squared_error: 0.9881 - val_loss: -4026386.0000 - val_mean_squared_error: 0.9896\n",
      "Epoch 48/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -4036407.7500 - mean_squared_error: 0.9882 - val_loss: -4180979.2500 - val_mean_squared_error: 0.9880\n",
      "Epoch 49/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -4274270.5000 - mean_squared_error: 0.9877 - val_loss: -4338529.5000 - val_mean_squared_error: 0.9887\n",
      "Epoch 50/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -4377641.5000 - mean_squared_error: 0.9879 - val_loss: -4497214.5000 - val_mean_squared_error: 0.9868\n",
      "Epoch 51/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -4556160.0000 - mean_squared_error: 0.9877 - val_loss: -4660085.5000 - val_mean_squared_error: 0.9885\n",
      "Epoch 52/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -4711596.5000 - mean_squared_error: 0.9879 - val_loss: -4823437.5000 - val_mean_squared_error: 0.9888\n",
      "Epoch 53/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -4923090.0000 - mean_squared_error: 0.9879 - val_loss: -4989183.5000 - val_mean_squared_error: 0.9896\n",
      "Epoch 54/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -5034001.5000 - mean_squared_error: 0.9884 - val_loss: -5158683.0000 - val_mean_squared_error: 0.9879\n",
      "Epoch 55/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -5226351.0000 - mean_squared_error: 0.9877 - val_loss: -5329393.0000 - val_mean_squared_error: 0.9881\n",
      "Epoch 56/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -5393098.5000 - mean_squared_error: 0.9880 - val_loss: -5502676.0000 - val_mean_squared_error: 0.9881\n",
      "Epoch 57/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -5563671.0000 - mean_squared_error: 0.9876 - val_loss: -5677485.0000 - val_mean_squared_error: 0.9880\n",
      "Epoch 58/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -5832608.5000 - mean_squared_error: 0.9874 - val_loss: -5855163.0000 - val_mean_squared_error: 0.9878\n",
      "Epoch 59/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -5927853.5000 - mean_squared_error: 0.9879 - val_loss: -6034507.0000 - val_mean_squared_error: 0.9876\n",
      "Epoch 60/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -6086244.5000 - mean_squared_error: 0.9879 - val_loss: -6215680.0000 - val_mean_squared_error: 0.9881\n",
      "Epoch 61/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -6344610.5000 - mean_squared_error: 0.9879 - val_loss: -6399725.5000 - val_mean_squared_error: 0.9891\n",
      "Epoch 62/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -6492160.0000 - mean_squared_error: 0.9880 - val_loss: -6586360.0000 - val_mean_squared_error: 0.9884\n",
      "Epoch 63/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -6700485.5000 - mean_squared_error: 0.9877 - val_loss: -6773935.5000 - val_mean_squared_error: 0.9892\n",
      "Epoch 64/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -6907470.5000 - mean_squared_error: 0.9882 - val_loss: -6964006.0000 - val_mean_squared_error: 0.9878\n",
      "Epoch 65/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -7025804.5000 - mean_squared_error: 0.9879 - val_loss: -7155504.0000 - val_mean_squared_error: 0.9872\n",
      "Epoch 66/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -7219007.5000 - mean_squared_error: 0.9877 - val_loss: -7350707.5000 - val_mean_squared_error: 0.9871\n",
      "Epoch 67/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -7491298.0000 - mean_squared_error: 0.9873 - val_loss: -7547326.0000 - val_mean_squared_error: 0.9879\n",
      "Epoch 68/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -7554815.5000 - mean_squared_error: 0.9876 - val_loss: -7744818.0000 - val_mean_squared_error: 0.9876\n",
      "Epoch 69/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -7836658.5000 - mean_squared_error: 0.9877 - val_loss: -7946065.0000 - val_mean_squared_error: 0.9875\n",
      "Epoch 70/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -8136964.5000 - mean_squared_error: 0.9877 - val_loss: -8149095.0000 - val_mean_squared_error: 0.9869\n",
      "Epoch 71/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -8211996.5000 - mean_squared_error: 0.9875 - val_loss: -8352762.0000 - val_mean_squared_error: 0.9889\n",
      "Epoch 72/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -8357557.0000 - mean_squared_error: 0.9882 - val_loss: -8560055.0000 - val_mean_squared_error: 0.9869\n",
      "Epoch 73/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -8749562.0000 - mean_squared_error: 0.9877 - val_loss: -8769150.0000 - val_mean_squared_error: 0.9872\n",
      "Epoch 74/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -8679823.0000 - mean_squared_error: 0.9878 - val_loss: -8978616.0000 - val_mean_squared_error: 0.9877\n",
      "Epoch 75/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -9059363.0000 - mean_squared_error: 0.9878 - val_loss: -9191750.0000 - val_mean_squared_error: 0.9860\n",
      "Epoch 76/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -9355045.0000 - mean_squared_error: 0.9872 - val_loss: -9406660.0000 - val_mean_squared_error: 0.9875\n",
      "Epoch 77/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -9608783.0000 - mean_squared_error: 0.9876 - val_loss: -9623767.0000 - val_mean_squared_error: 0.9877\n",
      "Epoch 78/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -9723205.0000 - mean_squared_error: 0.9877 - val_loss: -9842450.0000 - val_mean_squared_error: 0.9888\n",
      "Epoch 79/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -9794798.0000 - mean_squared_error: 0.9877 - val_loss: -10062492.0000 - val_mean_squared_error: 0.9884\n",
      "Epoch 80/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -10116120.0000 - mean_squared_error: 0.9880 - val_loss: -10285581.0000 - val_mean_squared_error: 0.9885\n",
      "Epoch 81/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -10340301.0000 - mean_squared_error: 0.9881 - val_loss: -10511140.0000 - val_mean_squared_error: 0.9891\n",
      "Epoch 82/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -10641501.0000 - mean_squared_error: 0.9879 - val_loss: -10737353.0000 - val_mean_squared_error: 0.9871\n",
      "Epoch 83/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -10799580.0000 - mean_squared_error: 0.9877 - val_loss: -10966376.0000 - val_mean_squared_error: 0.9876\n",
      "Epoch 84/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -11042780.0000 - mean_squared_error: 0.9877 - val_loss: -11196137.0000 - val_mean_squared_error: 0.9867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -11200189.0000 - mean_squared_error: 0.9871 - val_loss: -11428803.0000 - val_mean_squared_error: 0.9878\n",
      "Epoch 86/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -11890934.0000 - mean_squared_error: 0.9874 - val_loss: -11663981.0000 - val_mean_squared_error: 0.9877\n",
      "Epoch 87/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -11903683.0000 - mean_squared_error: 0.9876 - val_loss: -11900068.0000 - val_mean_squared_error: 0.9866\n",
      "Epoch 88/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -12055542.0000 - mean_squared_error: 0.9874 - val_loss: -12138121.0000 - val_mean_squared_error: 0.9867\n",
      "Epoch 89/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -12492969.0000 - mean_squared_error: 0.9870 - val_loss: -12379300.0000 - val_mean_squared_error: 0.9879\n",
      "Epoch 90/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -12411650.0000 - mean_squared_error: 0.9882 - val_loss: -12619944.0000 - val_mean_squared_error: 0.9865\n",
      "Epoch 91/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -12712821.0000 - mean_squared_error: 0.9870 - val_loss: -12864580.0000 - val_mean_squared_error: 0.9877\n",
      "Epoch 92/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -13065047.0000 - mean_squared_error: 0.9876 - val_loss: -13110574.0000 - val_mean_squared_error: 0.9880\n",
      "Epoch 93/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -13253928.0000 - mean_squared_error: 0.9876 - val_loss: -13358709.0000 - val_mean_squared_error: 0.9881\n",
      "Epoch 94/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -13549877.0000 - mean_squared_error: 0.9877 - val_loss: -13609035.0000 - val_mean_squared_error: 0.9884\n",
      "Epoch 95/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -13740314.0000 - mean_squared_error: 0.9875 - val_loss: -13860614.0000 - val_mean_squared_error: 0.9872\n",
      "Epoch 96/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -13932568.0000 - mean_squared_error: 0.9876 - val_loss: -14113225.0000 - val_mean_squared_error: 0.9867\n",
      "Epoch 97/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -14165424.0000 - mean_squared_error: 0.9878 - val_loss: -14369276.0000 - val_mean_squared_error: 0.9862\n",
      "Epoch 98/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -14466794.0000 - mean_squared_error: 0.9871 - val_loss: -14627787.0000 - val_mean_squared_error: 0.9875\n",
      "Epoch 99/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -14818151.0000 - mean_squared_error: 0.9879 - val_loss: -14886896.0000 - val_mean_squared_error: 0.9865\n",
      "Epoch 100/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -15099702.0000 - mean_squared_error: 0.9869 - val_loss: -15148858.0000 - val_mean_squared_error: 0.9883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17660037790>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train,x_train,epochs=100,batch_size=64,validation_data=(x_test,x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da3336cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions= autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "770b565e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse= np.mean(np.square(predictions-x_test),axis=1)\n",
    "threshold = np.percentile(mse, 95)\n",
    "outliers= mse > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03319cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outliers= np.sum(outliers)\n",
    "num_anomalies= np.sum(y_test[outliers]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb109841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers: 75\n",
      "Number of anomalies: 20\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of outliers: {num_outliers}')\n",
    "print(f'Number of anomalies: {num_anomalies}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1960b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
